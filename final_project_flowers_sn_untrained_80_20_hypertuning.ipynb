{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data source\n",
    "\n",
    "Data for download: https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
    "\n",
    "Resources used as reference:\n",
    "1) Training the image classifier to recognize different species of flowers:\n",
    "https://www.kaggle.com/dtosidis/flower-classifier-tensorflow\n",
    "  \n",
    "2) Loading and preprocessing an image dataset\n",
    "https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "3) Data augmentation\n",
    "https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "\n",
    "4) Image classification\n",
    "https://www.tensorflow.org/tutorials/images/classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\envs\\mlearning\\lib\\site-packages (from keras) (2.10.0)\n",
      "Collecting scipy>=0.14\n",
      "  Downloading scipy-1.5.2-cp38-cp38-win_amd64.whl (31.4 MB)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\envs\\mlearning\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\programdata\\anaconda3\\envs\\mlearning\\lib\\site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\envs\\mlearning\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: scipy, keras\n",
      "Successfully installed keras-2.4.3 scipy-1.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import pathlib\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import (\n",
    "    VGG19, \n",
    "    preprocess_input, \n",
    "    decode_predictions\n",
    ")\n",
    "\n",
    "#New method for test train split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/ShankersDocs/EDUCATION/RICE_Bootcamp_DataAnalytics/FinalProject_Img_Recognition_Flowers/Final_RICEproject_ImageRecognition_flowers\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'flower_photos'\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "# print(image_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification\n",
    "https://www.tensorflow.org/tutorials/images/classification?hl=zh-tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating datasets\n",
    "https://keras.io/examples/vision/image_classification_from_scratch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for training.\n"
     ]
    }
   ],
   "source": [
    "# When the subset below is defined as \"training\" the 0.2 validation split takes 80% of the data as the training set\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  'flower_photos',\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 367 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# When the subset below is defined as \"validation\" the 0.1 validation split takes 10% of the data as the validation set\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  'flower_photos',\n",
    "  validation_split=0.1,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 367 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# When the subset below is defined as \"validation\" the 0.1 validation split takes 10% of the data as the test set\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  'flower_photos',\n",
    "  validation_split=0.1,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling the data\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Rescaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the data (trainign and validation datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "normalized_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "normalized_val_ds =  val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_train_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autotune is done to cache data and make processing and resource mgmt more effieicient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_train_ds = normalized_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "normalized_val_ds = normalized_val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_classes = 5\n",
    "num_classes = len(class_names)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 (Sequential Model)\n",
    "https://www.tensorflow.org/guide/keras/sequential_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(img_height, img_width, 3)),\n",
    "  tf.keras.layers.Dense(128,activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data = val_ds, \n",
    "    epochs=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 (Sequential Model) Epoch sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(img_height, img_width, 3)),\n",
    "  tf.keras.layers.Dense(128,activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data = val_ds, \n",
    "    epochs=6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1a (Sequential Model) With Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1a = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(img_height, img_width, 3)),\n",
    "  tf.keras.layers.Dense(128,activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1a.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "92/92 [==============================] - 6s 67ms/step - loss: 9.3329 - accuracy: 0.2548 - val_loss: 1.5924 - val_accuracy: 0.2834\n",
      "Epoch 2/6\n",
      "92/92 [==============================] - 6s 66ms/step - loss: 1.5261 - accuracy: 0.3392 - val_loss: 1.5553 - val_accuracy: 0.3406\n",
      "Epoch 3/6\n",
      "92/92 [==============================] - 6s 65ms/step - loss: 1.5153 - accuracy: 0.3236 - val_loss: 1.5620 - val_accuracy: 0.3651\n",
      "Epoch 4/6\n",
      "92/92 [==============================] - 6s 65ms/step - loss: 1.4879 - accuracy: 0.3304 - val_loss: 1.5920 - val_accuracy: 0.4033\n",
      "Epoch 5/6\n",
      "92/92 [==============================] - 6s 65ms/step - loss: 1.4419 - accuracy: 0.3675 - val_loss: 1.5167 - val_accuracy: 0.4142\n",
      "Epoch 6/6\n",
      "92/92 [==============================] - 6s 68ms/step - loss: 1.4356 - accuracy: 0.3658 - val_loss: 1.5409 - val_accuracy: 0.4142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cfe05e7a00>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1a.fit(\n",
    "    normalized_train_ds,\n",
    "    validation_data = normalized_val_ds, \n",
    "    epochs=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1a.fit(\n",
    "    normalized_train_ds,\n",
    "    validation_data = normalized_val_ds, \n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 60s 657ms/step - loss: 1.3110 - accuracy: 0.4138 - val_loss: 1.1323 - val_accuracy: 0.5722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19042709e50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "92/92 [==============================] - 72s 786ms/step - loss: 1.3423 - accuracy: 0.4111 - val_loss: 1.0597 - val_accuracy: 0.5858\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 71s 771ms/step - loss: 1.0217 - accuracy: 0.6005 - val_loss: 1.0120 - val_accuracy: 0.6076\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 71s 772ms/step - loss: 0.8735 - accuracy: 0.6655 - val_loss: 0.9446 - val_accuracy: 0.6403\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 71s 772ms/step - loss: 0.6929 - accuracy: 0.7398 - val_loss: 0.9795 - val_accuracy: 0.6403\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 143s 2s/step - loss: 0.5100 - accuracy: 0.8191 - val_loss: 1.0341 - val_accuracy: 0.6676\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 157s 2s/step - loss: 0.4137 - accuracy: 0.8559 - val_loss: 1.2943 - val_accuracy: 0.6185\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 158s 2s/step - loss: 0.3521 - accuracy: 0.8740 - val_loss: 1.1599 - val_accuracy: 0.6540\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 150s 2s/step - loss: 0.3102 - accuracy: 0.8849 - val_loss: 1.2890 - val_accuracy: 0.6730\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 160s 2s/step - loss: 0.2404 - accuracy: 0.9152 - val_loss: 1.3638 - val_accuracy: 0.6730\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 161s 2s/step - loss: 0.2340 - accuracy: 0.9220 - val_loss: 1.7410 - val_accuracy: 0.6322\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 156s 2s/step - loss: 0.1591 - accuracy: 0.9472 - val_loss: 1.7341 - val_accuracy: 0.6458\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 150s 2s/step - loss: 0.0969 - accuracy: 0.9663 - val_loss: 1.9290 - val_accuracy: 0.6349\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 155s 2s/step - loss: 0.0741 - accuracy: 0.9806 - val_loss: 1.8242 - val_accuracy: 0.6294\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 170s 2s/step - loss: 0.0262 - accuracy: 0.9939 - val_loss: 2.1639 - val_accuracy: 0.6376\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 185s 2s/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 2.2884 - val_accuracy: 0.6267\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 185s 2s/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 2.5649 - val_accuracy: 0.6240\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 174s 2s/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 2.2545 - val_accuracy: 0.6594\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 160s 2s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.4649 - val_accuracy: 0.6540\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 158s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.5840 - val_accuracy: 0.6512\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 177s 2s/step - loss: 7.7852e-04 - accuracy: 1.0000 - val_loss: 2.6529 - val_accuracy: 0.6512\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 196s 2s/step - loss: 5.6774e-04 - accuracy: 1.0000 - val_loss: 2.7078 - val_accuracy: 0.6540\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 155s 2s/step - loss: 4.4252e-04 - accuracy: 1.0000 - val_loss: 2.7558 - val_accuracy: 0.6621\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 159s 2s/step - loss: 3.5709e-04 - accuracy: 1.0000 - val_loss: 2.7997 - val_accuracy: 0.6621\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 161s 2s/step - loss: 2.9789e-04 - accuracy: 1.0000 - val_loss: 2.8426 - val_accuracy: 0.6676\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 170s 2s/step - loss: 2.5231e-04 - accuracy: 1.0000 - val_loss: 2.8813 - val_accuracy: 0.6676\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 157s 2s/step - loss: 2.1665e-04 - accuracy: 1.0000 - val_loss: 2.9177 - val_accuracy: 0.6649\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 155s 2s/step - loss: 1.8990e-04 - accuracy: 1.0000 - val_loss: 2.9521 - val_accuracy: 0.6649\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 164s 2s/step - loss: 1.6723e-04 - accuracy: 1.0000 - val_loss: 2.9846 - val_accuracy: 0.6649\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 155s 2s/step - loss: 1.4841e-04 - accuracy: 1.0000 - val_loss: 3.0164 - val_accuracy: 0.6649\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 162s 2s/step - loss: 1.3281e-04 - accuracy: 1.0000 - val_loss: 3.0458 - val_accuracy: 0.6649\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 163s 2s/step - loss: 1.1978e-04 - accuracy: 1.0000 - val_loss: 3.0746 - val_accuracy: 0.6649\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 162s 2s/step - loss: 1.0800e-04 - accuracy: 1.0000 - val_loss: 3.1024 - val_accuracy: 0.6621\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 155s 2s/step - loss: 9.8047e-05 - accuracy: 1.0000 - val_loss: 3.1283 - val_accuracy: 0.6621\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 157s 2s/step - loss: 8.9182e-05 - accuracy: 1.0000 - val_loss: 3.1538 - val_accuracy: 0.6621\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 157s 2s/step - loss: 8.1367e-05 - accuracy: 1.0000 - val_loss: 3.1791 - val_accuracy: 0.6621\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 175s 2s/step - loss: 7.4669e-05 - accuracy: 1.0000 - val_loss: 3.2028 - val_accuracy: 0.6594\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 158s 2s/step - loss: 6.8628e-05 - accuracy: 1.0000 - val_loss: 3.2257 - val_accuracy: 0.6594\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 156s 2s/step - loss: 6.3146e-05 - accuracy: 1.0000 - val_loss: 3.2492 - val_accuracy: 0.6594\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 173s 2s/step - loss: 5.8178e-05 - accuracy: 1.0000 - val_loss: 3.2716 - val_accuracy: 0.6594\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 184s 2s/step - loss: 5.3765e-05 - accuracy: 1.0000 - val_loss: 3.2932 - val_accuracy: 0.6594\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 186s 2s/step - loss: 4.9692e-05 - accuracy: 1.0000 - val_loss: 3.3150 - val_accuracy: 0.6594\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 197s 2s/step - loss: 4.6100e-05 - accuracy: 1.0000 - val_loss: 3.3365 - val_accuracy: 0.6594\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 214s 2s/step - loss: 4.2701e-05 - accuracy: 1.0000 - val_loss: 3.3574 - val_accuracy: 0.6594\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 191s 2s/step - loss: 3.9645e-05 - accuracy: 1.0000 - val_loss: 3.3774 - val_accuracy: 0.6594\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 162s 2s/step - loss: 3.6843e-05 - accuracy: 1.0000 - val_loss: 3.3974 - val_accuracy: 0.6594\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 171s 2s/step - loss: 3.4317e-05 - accuracy: 1.0000 - val_loss: 3.4175 - val_accuracy: 0.6594\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 157s 2s/step - loss: 3.1977e-05 - accuracy: 1.0000 - val_loss: 3.4358 - val_accuracy: 0.6567\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 159s 2s/step - loss: 2.9837e-05 - accuracy: 1.0000 - val_loss: 3.4551 - val_accuracy: 0.6540\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 163s 2s/step - loss: 2.7815e-05 - accuracy: 1.0000 - val_loss: 3.4739 - val_accuracy: 0.6567\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 160s 2s/step - loss: 2.6040e-05 - accuracy: 1.0000 - val_loss: 3.4919 - val_accuracy: 0.6567\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 163s 2s/step - loss: 2.4375e-05 - accuracy: 1.0000 - val_loss: 3.5098 - val_accuracy: 0.6567\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 158s 2s/step - loss: 2.2794e-05 - accuracy: 1.0000 - val_loss: 3.5277 - val_accuracy: 0.6567\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 166s 2s/step - loss: 2.1385e-05 - accuracy: 1.0000 - val_loss: 3.5455 - val_accuracy: 0.6567\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 155s 2s/step - loss: 2.0049e-05 - accuracy: 1.0000 - val_loss: 3.5632 - val_accuracy: 0.6567\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 158s 2s/step - loss: 1.8817e-05 - accuracy: 1.0000 - val_loss: 3.5808 - val_accuracy: 0.6567\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 159s 2s/step - loss: 1.7656e-05 - accuracy: 1.0000 - val_loss: 3.5980 - val_accuracy: 0.6540\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 173s 2s/step - loss: 1.6594e-05 - accuracy: 1.0000 - val_loss: 3.6163 - val_accuracy: 0.6540\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 159s 2s/step - loss: 1.5604e-05 - accuracy: 1.0000 - val_loss: 3.6324 - val_accuracy: 0.6512\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 161s 2s/step - loss: 1.4666e-05 - accuracy: 1.0000 - val_loss: 3.6503 - val_accuracy: 0.6485\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 165s 2s/step - loss: 1.3810e-05 - accuracy: 1.0000 - val_loss: 3.6674 - val_accuracy: 0.6485\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 161s 2s/step - loss: 1.2992e-05 - accuracy: 1.0000 - val_loss: 3.6843 - val_accuracy: 0.6485\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 168s 2s/step - loss: 1.2237e-05 - accuracy: 1.0000 - val_loss: 3.7011 - val_accuracy: 0.6458\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 158s 2s/step - loss: 1.1522e-05 - accuracy: 1.0000 - val_loss: 3.7181 - val_accuracy: 0.6458\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 175s 2s/step - loss: 1.0870e-05 - accuracy: 1.0000 - val_loss: 3.7351 - val_accuracy: 0.6458\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 187s 2s/step - loss: 1.0239e-05 - accuracy: 1.0000 - val_loss: 3.7518 - val_accuracy: 0.6485\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 183s 2s/step - loss: 9.6578e-06 - accuracy: 1.0000 - val_loss: 3.7686 - val_accuracy: 0.6485\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 182s 2s/step - loss: 9.1037e-06 - accuracy: 1.0000 - val_loss: 3.7861 - val_accuracy: 0.6485\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 156s 2s/step - loss: 8.5946e-06 - accuracy: 1.0000 - val_loss: 3.8018 - val_accuracy: 0.6485\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 158s 2s/step - loss: 8.1133e-06 - accuracy: 1.0000 - val_loss: 3.8185 - val_accuracy: 0.6485\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 156s 2s/step - loss: 7.6575e-06 - accuracy: 1.0000 - val_loss: 3.8348 - val_accuracy: 0.6485\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 168s 2s/step - loss: 7.2272e-06 - accuracy: 1.0000 - val_loss: 3.8516 - val_accuracy: 0.6485\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 157s 2s/step - loss: 6.8242e-06 - accuracy: 1.0000 - val_loss: 3.8682 - val_accuracy: 0.6485\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 162s 2s/step - loss: 6.4446e-06 - accuracy: 1.0000 - val_loss: 3.8846 - val_accuracy: 0.6485\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 169s 2s/step - loss: 6.0875e-06 - accuracy: 1.0000 - val_loss: 3.9013 - val_accuracy: 0.6485\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 162s 2s/step - loss: 5.7511e-06 - accuracy: 1.0000 - val_loss: 3.9182 - val_accuracy: 0.6485\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 156s 2s/step - loss: 5.4339e-06 - accuracy: 1.0000 - val_loss: 3.9340 - val_accuracy: 0.6485\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 160s 2s/step - loss: 5.1391e-06 - accuracy: 1.0000 - val_loss: 3.9510 - val_accuracy: 0.6485\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 167s 2s/step - loss: 4.8565e-06 - accuracy: 1.0000 - val_loss: 3.9679 - val_accuracy: 0.6485\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 159s 2s/step - loss: 4.5910e-06 - accuracy: 1.0000 - val_loss: 3.9841 - val_accuracy: 0.6485\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 159s 2s/step - loss: 4.3407e-06 - accuracy: 1.0000 - val_loss: 4.0009 - val_accuracy: 0.6485\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 158s 2s/step - loss: 4.1024e-06 - accuracy: 1.0000 - val_loss: 4.0170 - val_accuracy: 0.6485\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 167s 2s/step - loss: 3.8815e-06 - accuracy: 1.0000 - val_loss: 4.0336 - val_accuracy: 0.6485\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 156s 2s/step - loss: 3.6739e-06 - accuracy: 1.0000 - val_loss: 4.0492 - val_accuracy: 0.6512\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 158s 2s/step - loss: 3.4738e-06 - accuracy: 1.0000 - val_loss: 4.0660 - val_accuracy: 0.6512\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 159s 2s/step - loss: 3.2838e-06 - accuracy: 1.0000 - val_loss: 4.0826 - val_accuracy: 0.6512\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 165s 2s/step - loss: 3.1068e-06 - accuracy: 1.0000 - val_loss: 4.0990 - val_accuracy: 0.6512\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 158s 2s/step - loss: 2.9403e-06 - accuracy: 1.0000 - val_loss: 4.1155 - val_accuracy: 0.6512\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 60s 650ms/step - loss: 2.7811e-06 - accuracy: 1.0000 - val_loss: 4.1319 - val_accuracy: 0.6512\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 47s 515ms/step - loss: 2.6299e-06 - accuracy: 1.0000 - val_loss: 4.1495 - val_accuracy: 0.6512\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 70s 765ms/step - loss: 2.4871e-06 - accuracy: 1.0000 - val_loss: 4.1663 - val_accuracy: 0.6512\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 71s 773ms/step - loss: 2.3513e-06 - accuracy: 1.0000 - val_loss: 4.1831 - val_accuracy: 0.6512\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 71s 768ms/step - loss: 2.2234e-06 - accuracy: 1.0000 - val_loss: 4.2000 - val_accuracy: 0.6485\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 1009s 11s/step - loss: 2.1031e-06 - accuracy: 1.0000 - val_loss: 4.2170 - val_accuracy: 0.6458\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 87s 950ms/step - loss: 1.9867e-06 - accuracy: 1.0000 - val_loss: 4.2343 - val_accuracy: 0.6458\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 50s 539ms/step - loss: 1.8819e-06 - accuracy: 1.0000 - val_loss: 4.2500 - val_accuracy: 0.6458\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 47s 513ms/step - loss: 1.7801e-06 - accuracy: 1.0000 - val_loss: 4.2671 - val_accuracy: 0.6458\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 48s 520ms/step - loss: 1.6843e-06 - accuracy: 1.0000 - val_loss: 4.2846 - val_accuracy: 0.6458\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 47s 509ms/step - loss: 1.5927e-06 - accuracy: 1.0000 - val_loss: 4.3013 - val_accuracy: 0.6458\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 49s 528ms/step - loss: 1.5075e-06 - accuracy: 1.0000 - val_loss: 4.3183 - val_accuracy: 0.6458\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 51s 552ms/step - loss: 1.4260e-06 - accuracy: 1.0000 - val_loss: 4.3350 - val_accuracy: 0.6458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x167f0f8a310>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY MODEL WITH DIFFERENT LOSS PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Value for attr 'T' of string is not in the list of allowed values: float, double, int32, uint8, int16, int8, complex64, int64, qint8, quint8, qint32, bfloat16, uint16, complex128, half, uint32, uint64\n\t; NodeDef: {{node Sum}}; Op<name=Sum; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]> [Op:Sum]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-724baa2e8991>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model_2.compile(\n\u001b[0;32m      2\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m   metrics=['accuracy'])\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(y_true, y_pred, from_logits, label_smoothing)\u001b[0m\n\u001b[0;32m   1533\u001b[0m   y_true = smart_cond.smart_cond(label_smoothing,\n\u001b[0;32m   1534\u001b[0m                                  _smooth_labels, lambda: y_true)\n\u001b[1;32m-> 1535\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m   4702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4703\u001b[0m   \u001b[1;31m# scale preds so that the class probas of each sample sum to 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4704\u001b[1;33m   \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4705\u001b[0m   \u001b[1;31m# Compute cross entropy from probabilities.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4706\u001b[0m   \u001b[0mepsilon_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_constant_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mreduce_sum\u001b[1;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[0;32m   1980\u001b[0m   \"\"\"\n\u001b[0;32m   1981\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1982\u001b[1;33m   return reduce_sum_with_dims(input_tensor, axis, keepdims, name,\n\u001b[0m\u001b[0;32m   1983\u001b[0m                               _ReductionDims(input_tensor, axis))\n\u001b[0;32m   1984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mreduce_sum_with_dims\u001b[1;34m(input_tensor, axis, keepdims, name, dims)\u001b[0m\n\u001b[0;32m   1992\u001b[0m   return _may_reduce_to_scalar(\n\u001b[0;32m   1993\u001b[0m       \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1994\u001b[1;33m       gen_math_ops._sum(input_tensor, dims, keepdims, name=name))\n\u001b[0m\u001b[0;32m   1995\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[0;32m  10521\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10522\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10523\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10524\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10525\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6842\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6843\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6844\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Value for attr 'T' of string is not in the list of allowed values: float, double, int32, uint8, int16, int8, complex64, int64, qint8, quint8, qint32, bfloat16, uint16, complex128, half, uint32, uint64\n\t; NodeDef: {{node Sum}}; Op<name=Sum; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]> [Op:Sum]"
     ]
    }
   ],
   "source": [
    "model_2.compile(\n",
    "  optimizer='adam',\n",
    "  loss = tf.keras.losses.categorical_crossentropy(class_names,class_names),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 180, 180, 3), (None,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-4d4df435b495>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model_2.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m   \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "model_2.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-378732ef5219>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/ShankersDocs/EDUCATION/RICE_Bootcamp_DataAnalytics/FinalProject_Img_Recognition_Flowers/Final_RICEproject_ImageRecognition_flowers\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\Mlearning\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     active environment : Mlearning\n",
      "    active env location : C:\\ProgramData\\Anaconda3\\envs\\Mlearning\n",
      "            shell level : 2\n",
      "       user config file : C:\\Users\\nairs\\.condarc\n",
      " populated config files : C:\\Users\\nairs\\.condarc\n",
      "          conda version : 4.8.3\n",
      "    conda-build version : 3.18.11\n",
      "         python version : 3.7.6.final.0\n",
      "       virtual packages : __cuda=10.2\n",
      "       base environment : C:\\ProgramData\\Anaconda3  (writable)\n",
      "           channel URLs : https://repo.anaconda.com/pkgs/main/win-64\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\n",
      "                          https://repo.anaconda.com/pkgs/r/win-64\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\n",
      "                          https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "                          https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "          package cache : C:\\ProgramData\\Anaconda3\\pkgs\n",
      "                          C:\\Users\\nairs\\.conda\\pkgs\n",
      "                          C:\\Users\\nairs\\AppData\\Local\\conda\\conda\\pkgs\n",
      "       envs directories : C:\\ProgramData\\Anaconda3\\envs\n",
      "                          C:\\Users\\nairs\\.conda\\envs\n",
      "                          C:\\Users\\nairs\\AppData\\Local\\conda\\conda\\envs\n",
      "               platform : win-64\n",
      "             user-agent : conda/4.8.3 requests/2.22.0 CPython/3.7.6 Windows/10 Windows/10.0.18362\n",
      "          administrator : True\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/nairs/Desktop/model_2\\assets\n"
     ]
    }
   ],
   "source": [
    "model_2.save('C:/Users/nairs/Desktop/model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
