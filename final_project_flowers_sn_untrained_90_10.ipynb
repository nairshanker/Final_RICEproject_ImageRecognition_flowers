{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data source\n",
    "\n",
    "Data for download: https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
    "\n",
    "Resources used as reference:\n",
    "1) Training the image classifier to recognize different species of flowers:\n",
    "https://www.kaggle.com/dtosidis/flower-classifier-tensorflow\n",
    "  \n",
    "2) Loading and preprocessing an image dataset\n",
    "https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "3) Data augmentation\n",
    "https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "\n",
    "4) Image classification\n",
    "https://www.tensorflow.org/tutorials/images/classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import pathlib\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import (\n",
    "    VGG19, \n",
    "    preprocess_input, \n",
    "    decode_predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/ShankersDocs/EDUCATION/RICE_Bootcamp_DataAnalytics/FinalProject_Img_Recognition_Flowers/Final_RICEproject_ImageRecognition_flowers\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'flower_photos'\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "# print(image_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification\n",
    "https://www.tensorflow.org/tutorials/images/classification?hl=zh-tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating datasets\n",
    "https://keras.io/examples/vision/image_classification_from_scratch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 3487 files for training.\n"
     ]
    }
   ],
   "source": [
    "# When the subset below is defined as \"training\" the 0.2 validation split takes 80% of the data as the training set\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  'flower_photos',\n",
    "  validation_split=0.05,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 183 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# When the subset below is defined as \"validation\" the 0.1 validation split takes 10% of the data as the validation set\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  'flower_photos',\n",
    "  validation_split=0.05,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 367 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# When the subset below is defined as \"validation\" the 0.1 validation split takes 10% of the data as the test set\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  'flower_photos',\n",
    "  validation_split=0.1,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling the data\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Rescaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the data (trainign and validation datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "normalized_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "normalized_val_ds =  val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_train_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autotune is done to cache data and make processing and resource mgmt more effieicient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_train_ds = normalized_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "normalized_val_ds = normalized_val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_classes = 5\n",
    "num_classes = len(class_names)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 (Sequential Model)\n",
    "https://www.tensorflow.org/guide/keras/sequential_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(img_height, img_width, 3)),\n",
    "  tf.keras.layers.Dense(128,activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "109/109 [==============================] - 25s 230ms/step - loss: 3137.6106 - accuracy: 0.3324 - val_loss: 1531.6011 - val_accuracy: 0.3443\n",
      "Epoch 2/16\n",
      "109/109 [==============================] - 7s 65ms/step - loss: 910.4540 - accuracy: 0.4118 - val_loss: 782.0704 - val_accuracy: 0.3607\n",
      "Epoch 3/16\n",
      "109/109 [==============================] - 7s 64ms/step - loss: 837.4989 - accuracy: 0.4310 - val_loss: 780.0682 - val_accuracy: 0.3661\n",
      "Epoch 4/16\n",
      "109/109 [==============================] - 7s 64ms/step - loss: 650.1601 - accuracy: 0.4677 - val_loss: 918.6453 - val_accuracy: 0.3880\n",
      "Epoch 5/16\n",
      "109/109 [==============================] - 7s 63ms/step - loss: 583.7142 - accuracy: 0.4792 - val_loss: 530.8185 - val_accuracy: 0.3880\n",
      "Epoch 6/16\n",
      "109/109 [==============================] - 7s 63ms/step - loss: 334.7931 - accuracy: 0.5053 - val_loss: 605.9751 - val_accuracy: 0.3224\n",
      "Epoch 7/16\n",
      "109/109 [==============================] - 7s 65ms/step - loss: 384.2635 - accuracy: 0.4677 - val_loss: 499.2506 - val_accuracy: 0.3333\n",
      "Epoch 8/16\n",
      "109/109 [==============================] - 5s 47ms/step - loss: 236.6864 - accuracy: 0.4356 - val_loss: 4.0871 - val_accuracy: 0.2350\n",
      "Epoch 9/16\n",
      "109/109 [==============================] - 5s 48ms/step - loss: 1.7828 - accuracy: 0.2254 - val_loss: 2.0467 - val_accuracy: 0.2295\n",
      "Epoch 10/16\n",
      "109/109 [==============================] - 5s 48ms/step - loss: 1.6179 - accuracy: 0.2277 - val_loss: 2.0593 - val_accuracy: 0.2514\n",
      "Epoch 11/16\n",
      "109/109 [==============================] - 5s 46ms/step - loss: 1.6095 - accuracy: 0.2529 - val_loss: 2.0713 - val_accuracy: 0.2514\n",
      "Epoch 12/16\n",
      "109/109 [==============================] - 5s 44ms/step - loss: 1.6114 - accuracy: 0.2521 - val_loss: 1.9972 - val_accuracy: 0.2514\n",
      "Epoch 13/16\n",
      "109/109 [==============================] - 5s 44ms/step - loss: 1.5926 - accuracy: 0.2521 - val_loss: 1.9362 - val_accuracy: 0.2514\n",
      "Epoch 14/16\n",
      "109/109 [==============================] - 5s 44ms/step - loss: 1.5916 - accuracy: 0.2515 - val_loss: 1.8754 - val_accuracy: 0.2514\n",
      "Epoch 15/16\n",
      "109/109 [==============================] - 5s 44ms/step - loss: 1.5915 - accuracy: 0.2515 - val_loss: 1.7911 - val_accuracy: 0.2514\n",
      "Epoch 16/16\n",
      "109/109 [==============================] - 5s 46ms/step - loss: 1.5894 - accuracy: 0.2518 - val_loss: 1.7565 - val_accuracy: 0.2514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19b2a952a30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data = val_ds, \n",
    "    epochs=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 (Sequential Model) Epoch sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(img_height, img_width, 3)),\n",
    "  tf.keras.layers.Dense(128,activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "109/109 [==============================] - 5s 44ms/step - loss: 1507.9851 - accuracy: 0.2108 - val_loss: 1.6087 - val_accuracy: 0.1913\n",
      "Epoch 2/6\n",
      "109/109 [==============================] - 5s 43ms/step - loss: 1.6145 - accuracy: 0.2314 - val_loss: 1.6067 - val_accuracy: 0.2404\n",
      "Epoch 3/6\n",
      "109/109 [==============================] - 5s 44ms/step - loss: 1.6101 - accuracy: 0.2461 - val_loss: 1.6051 - val_accuracy: 0.2404\n",
      "Epoch 4/6\n",
      "109/109 [==============================] - 5s 44ms/step - loss: 1.6057 - accuracy: 0.2455 - val_loss: 1.6039 - val_accuracy: 0.2404\n",
      "Epoch 5/6\n",
      "109/109 [==============================] - 5s 43ms/step - loss: 1.6021 - accuracy: 0.2452 - val_loss: 1.6032 - val_accuracy: 0.2404\n",
      "Epoch 6/6\n",
      "109/109 [==============================] - 5s 44ms/step - loss: 1.6012 - accuracy: 0.2452 - val_loss: 1.6027 - val_accuracy: 0.2404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19b3040c9a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data = val_ds, \n",
    "    epochs=6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1a (Sequential Model) With Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1a = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(img_height, img_width, 3)),\n",
    "  tf.keras.layers.Dense(128,activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1a.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "109/109 [==============================] - 11s 97ms/step - loss: 7.0116 - accuracy: 0.2114 - val_loss: 1.6089 - val_accuracy: 0.2404\n",
      "Epoch 2/6\n",
      "109/109 [==============================] - 5s 43ms/step - loss: 1.6065 - accuracy: 0.2532 - val_loss: 1.6051 - val_accuracy: 0.2404\n",
      "Epoch 3/6\n",
      "109/109 [==============================] - 5s 43ms/step - loss: 1.5882 - accuracy: 0.2656 - val_loss: 1.6695 - val_accuracy: 0.2514\n",
      "Epoch 4/6\n",
      "109/109 [==============================] - 5s 44ms/step - loss: 1.5634 - accuracy: 0.2756 - val_loss: 1.6035 - val_accuracy: 0.2404\n",
      "Epoch 5/6\n",
      "109/109 [==============================] - 5s 44ms/step - loss: 1.5996 - accuracy: 0.2466 - val_loss: 1.6029 - val_accuracy: 0.2404\n",
      "Epoch 6/6\n",
      "109/109 [==============================] - 5s 44ms/step - loss: 1.5959 - accuracy: 0.2492 - val_loss: 1.5995 - val_accuracy: 0.2459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19b306b4970>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1a.fit(\n",
    "    normalized_train_ds,\n",
    "    validation_data = normalized_val_ds, \n",
    "    epochs=6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      " 19/109 [====>.........................] - ETA: 56s - loss: 1.6414 - accuracy: 0.2039"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-4d4df435b495>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model_2.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m   \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_2.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "109/109 [==============================] - 53s 486ms/step - loss: 0.2391 - accuracy: 0.9191 - val_loss: 1.1211 - val_accuracy: 0.6776\n",
      "Epoch 2/8\n",
      "109/109 [==============================] - 53s 485ms/step - loss: 0.1985 - accuracy: 0.9297 - val_loss: 1.4030 - val_accuracy: 0.6230\n",
      "Epoch 3/8\n",
      "109/109 [==============================] - 54s 496ms/step - loss: 0.1577 - accuracy: 0.9484 - val_loss: 1.5751 - val_accuracy: 0.5956\n",
      "Epoch 4/8\n",
      "109/109 [==============================] - 58s 534ms/step - loss: 0.1120 - accuracy: 0.9667 - val_loss: 1.5745 - val_accuracy: 0.6557\n",
      "Epoch 5/8\n",
      "109/109 [==============================] - 55s 502ms/step - loss: 0.0855 - accuracy: 0.9751 - val_loss: 1.7683 - val_accuracy: 0.6667\n",
      "Epoch 6/8\n",
      "109/109 [==============================] - 56s 512ms/step - loss: 0.0599 - accuracy: 0.9828 - val_loss: 1.8698 - val_accuracy: 0.6612\n",
      "Epoch 7/8\n",
      "109/109 [==============================] - 53s 490ms/step - loss: 0.0277 - accuracy: 0.9937 - val_loss: 2.3742 - val_accuracy: 0.6120\n",
      "Epoch 8/8\n",
      "109/109 [==============================] - 57s 520ms/step - loss: 0.0201 - accuracy: 0.9968 - val_loss: 2.1191 - val_accuracy: 0.6503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19b2a9aed30>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "109/109 [==============================] - 55s 505ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 2.0296 - val_accuracy: 0.6831\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 56s 512ms/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 2.0692 - val_accuracy: 0.6885\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 54s 497ms/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 2.0980 - val_accuracy: 0.6995\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 54s 492ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 2.1237 - val_accuracy: 0.6940\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 54s 491ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 2.1358 - val_accuracy: 0.7049\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 53s 491ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 2.1403 - val_accuracy: 0.7049\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 54s 500ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 2.1474 - val_accuracy: 0.7049\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 56s 510ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 2.1566 - val_accuracy: 0.7049\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 64s 589ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 2.1560 - val_accuracy: 0.6995\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 61s 562ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 2.1269 - val_accuracy: 0.7104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19bf56e3a30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "109/109 [==============================] - 61s 557ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 2.1815 - val_accuracy: 0.6940\n",
      "Epoch 2/12\n",
      "109/109 [==============================] - 60s 548ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 2.2163 - val_accuracy: 0.6885\n",
      "Epoch 3/12\n",
      "109/109 [==============================] - 64s 590ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 2.1172 - val_accuracy: 0.7213\n",
      "Epoch 4/12\n",
      "109/109 [==============================] - 62s 565ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 2.1750 - val_accuracy: 0.6940\n",
      "Epoch 5/12\n",
      "109/109 [==============================] - 58s 533ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 2.1796 - val_accuracy: 0.6885\n",
      "Epoch 6/12\n",
      "109/109 [==============================] - 58s 529ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 2.1707 - val_accuracy: 0.6885\n",
      "Epoch 7/12\n",
      "109/109 [==============================] - 65s 593ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 2.1801 - val_accuracy: 0.6940\n",
      "Epoch 8/12\n",
      "109/109 [==============================] - 70s 640ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 2.2166 - val_accuracy: 0.6831\n",
      "Epoch 9/12\n",
      "109/109 [==============================] - 64s 586ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 2.1799 - val_accuracy: 0.6940\n",
      "Epoch 10/12\n",
      "109/109 [==============================] - 63s 581ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 2.2149 - val_accuracy: 0.6831\n",
      "Epoch 11/12\n",
      "109/109 [==============================] - 63s 578ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 2.2139 - val_accuracy: 0.6885\n",
      "Epoch 12/12\n",
      "109/109 [==============================] - 61s 564ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 2.2157 - val_accuracy: 0.6995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19bf5708d90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "109/109 [==============================] - 62s 564ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 2.1759 - val_accuracy: 0.7049\n",
      "Epoch 2/14\n",
      "109/109 [==============================] - 65s 595ms/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 2.6731 - val_accuracy: 0.6175\n",
      "Epoch 3/14\n",
      "109/109 [==============================] - 65s 593ms/step - loss: 0.2473 - accuracy: 0.9252 - val_loss: 1.7773 - val_accuracy: 0.6831\n",
      "Epoch 4/14\n",
      "109/109 [==============================] - 69s 633ms/step - loss: 0.0882 - accuracy: 0.9736 - val_loss: 2.2340 - val_accuracy: 0.6393\n",
      "Epoch 5/14\n",
      "109/109 [==============================] - 63s 575ms/step - loss: 0.0423 - accuracy: 0.9868 - val_loss: 3.1447 - val_accuracy: 0.5847\n",
      "Epoch 6/14\n",
      "109/109 [==============================] - 58s 531ms/step - loss: 0.0532 - accuracy: 0.9837 - val_loss: 2.4214 - val_accuracy: 0.6175\n",
      "Epoch 7/14\n",
      "109/109 [==============================] - 58s 530ms/step - loss: 0.0368 - accuracy: 0.9914 - val_loss: 2.3854 - val_accuracy: 0.6557\n",
      "Epoch 8/14\n",
      "109/109 [==============================] - 58s 530ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 2.3353 - val_accuracy: 0.6776\n",
      "Epoch 9/14\n",
      "109/109 [==============================] - 57s 524ms/step - loss: 0.0175 - accuracy: 0.9960 - val_loss: 2.5013 - val_accuracy: 0.6667\n",
      "Epoch 10/14\n",
      "109/109 [==============================] - 57s 525ms/step - loss: 0.0163 - accuracy: 0.9960 - val_loss: 2.5912 - val_accuracy: 0.6557\n",
      "Epoch 11/14\n",
      "109/109 [==============================] - 58s 530ms/step - loss: 0.0148 - accuracy: 0.9968 - val_loss: 2.2865 - val_accuracy: 0.6885\n",
      "Epoch 12/14\n",
      "109/109 [==============================] - 58s 530ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 2.3942 - val_accuracy: 0.6831\n",
      "Epoch 13/14\n",
      "109/109 [==============================] - 61s 556ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 2.1539 - val_accuracy: 0.6831\n",
      "Epoch 14/14\n",
      "109/109 [==============================] - 58s 530ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 2.1879 - val_accuracy: 0.7104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19bf5708490>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=14\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "109/109 [==============================] - 45s 411ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 2.2160 - val_accuracy: 0.7049\n",
      "Epoch 2/16\n",
      "109/109 [==============================] - 46s 421ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 2.2378 - val_accuracy: 0.6995\n",
      "Epoch 3/16\n",
      "109/109 [==============================] - 50s 461ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 2.2653 - val_accuracy: 0.7104\n",
      "Epoch 4/16\n",
      "109/109 [==============================] - 51s 467ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 2.2614 - val_accuracy: 0.7049\n",
      "Epoch 5/16\n",
      "109/109 [==============================] - 54s 494ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 2.2810 - val_accuracy: 0.6940\n",
      "Epoch 6/16\n",
      "109/109 [==============================] - 50s 462ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 2.2835 - val_accuracy: 0.6940\n",
      "Epoch 7/16\n",
      "109/109 [==============================] - 52s 477ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 2.2977 - val_accuracy: 0.6995\n",
      "Epoch 8/16\n",
      "109/109 [==============================] - 53s 485ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 2.3038 - val_accuracy: 0.6995\n",
      "Epoch 9/16\n",
      "109/109 [==============================] - 57s 522ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 2.3089 - val_accuracy: 0.7049\n",
      "Epoch 10/16\n",
      "109/109 [==============================] - 62s 568ms/step - loss: 9.6267e-04 - accuracy: 0.9994 - val_loss: 2.3120 - val_accuracy: 0.7049\n",
      "Epoch 11/16\n",
      "109/109 [==============================] - 56s 510ms/step - loss: 9.1920e-04 - accuracy: 0.9994 - val_loss: 2.3093 - val_accuracy: 0.7104\n",
      "Epoch 12/16\n",
      "109/109 [==============================] - 54s 499ms/step - loss: 8.8238e-04 - accuracy: 0.9994 - val_loss: 2.3167 - val_accuracy: 0.7158\n",
      "Epoch 13/16\n",
      "109/109 [==============================] - 54s 500ms/step - loss: 8.5105e-04 - accuracy: 0.9994 - val_loss: 2.3262 - val_accuracy: 0.7158\n",
      "Epoch 14/16\n",
      "109/109 [==============================] - 61s 556ms/step - loss: 8.2176e-04 - accuracy: 0.9994 - val_loss: 2.3283 - val_accuracy: 0.7104\n",
      "Epoch 15/16\n",
      "109/109 [==============================] - 55s 506ms/step - loss: 7.9744e-04 - accuracy: 0.9994 - val_loss: 2.3342 - val_accuracy: 0.7104\n",
      "Epoch 16/16\n",
      "109/109 [==============================] - 55s 502ms/step - loss: 7.7399e-04 - accuracy: 0.9994 - val_loss: 2.3402 - val_accuracy: 0.7158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19bef3b4b20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "109/109 [==============================] - 54s 494ms/step - loss: 8.7196e-04 - accuracy: 0.9994 - val_loss: 2.3502 - val_accuracy: 0.7158\n",
      "Epoch 2/18\n",
      "109/109 [==============================] - 57s 524ms/step - loss: 7.9307e-04 - accuracy: 0.9994 - val_loss: 2.3476 - val_accuracy: 0.7104\n",
      "Epoch 3/18\n",
      "109/109 [==============================] - 55s 508ms/step - loss: 7.3871e-04 - accuracy: 0.9994 - val_loss: 2.3512 - val_accuracy: 0.7104\n",
      "Epoch 4/18\n",
      "109/109 [==============================] - 58s 532ms/step - loss: 7.0824e-04 - accuracy: 0.9994 - val_loss: 2.3576 - val_accuracy: 0.7104\n",
      "Epoch 5/18\n",
      "109/109 [==============================] - 58s 529ms/step - loss: 6.8425e-04 - accuracy: 0.9994 - val_loss: 2.3667 - val_accuracy: 0.7104\n",
      "Epoch 6/18\n",
      "109/109 [==============================] - 56s 513ms/step - loss: 6.7293e-04 - accuracy: 0.9994 - val_loss: 2.3699 - val_accuracy: 0.7158\n",
      "Epoch 7/18\n",
      "109/109 [==============================] - 55s 501ms/step - loss: 6.4788e-04 - accuracy: 0.9994 - val_loss: 2.3857 - val_accuracy: 0.7104\n",
      "Epoch 8/18\n",
      "109/109 [==============================] - 59s 538ms/step - loss: 6.3007e-04 - accuracy: 0.9994 - val_loss: 2.3913 - val_accuracy: 0.7104\n",
      "Epoch 9/18\n",
      "109/109 [==============================] - 55s 502ms/step - loss: 6.1546e-04 - accuracy: 0.9994 - val_loss: 2.3982 - val_accuracy: 0.7049\n",
      "Epoch 10/18\n",
      "109/109 [==============================] - 58s 532ms/step - loss: 5.9994e-04 - accuracy: 0.9994 - val_loss: 2.3979 - val_accuracy: 0.7049\n",
      "Epoch 11/18\n",
      "109/109 [==============================] - 59s 543ms/step - loss: 5.8657e-04 - accuracy: 0.9994 - val_loss: 2.3918 - val_accuracy: 0.7104\n",
      "Epoch 12/18\n",
      "109/109 [==============================] - 57s 524ms/step - loss: 5.7543e-04 - accuracy: 0.9994 - val_loss: 2.4000 - val_accuracy: 0.7049\n",
      "Epoch 13/18\n",
      "109/109 [==============================] - 55s 502ms/step - loss: 5.6407e-04 - accuracy: 0.9994 - val_loss: 2.4010 - val_accuracy: 0.7104\n",
      "Epoch 14/18\n",
      "109/109 [==============================] - 75s 687ms/step - loss: 8.2325e-04 - accuracy: 0.9994 - val_loss: 2.4154 - val_accuracy: 0.7158\n",
      "Epoch 15/18\n",
      "109/109 [==============================] - 83s 763ms/step - loss: 0.1767 - accuracy: 0.9501 - val_loss: 1.7480 - val_accuracy: 0.6393\n",
      "Epoch 16/18\n",
      "109/109 [==============================] - 83s 761ms/step - loss: 0.0838 - accuracy: 0.9736 - val_loss: 2.5300 - val_accuracy: 0.6612\n",
      "Epoch 17/18\n",
      "109/109 [==============================] - 81s 746ms/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 2.4569 - val_accuracy: 0.6557\n",
      "Epoch 18/18\n",
      "109/109 [==============================] - 79s 722ms/step - loss: 0.0142 - accuracy: 0.9968 - val_loss: 2.1830 - val_accuracy: 0.6776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19bf56e5b50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=18\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 88s 810ms/step - loss: 1.2256 - accuracy: 0.4832 - val_loss: 1.0711 - val_accuracy: 0.6011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19bf63db7c0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Failed to create a NewWriteableFile: model_2\\variables\\variables_temp_d8965615a90945f2be889de340f7d15d/part-00000-of-00001.data-00000-of-00001.tempstate18400128457331505972 : The system cannot find the path specified.\r\n; No such process [Op:SaveV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-3a244113cce6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m   1976\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1977\u001b[0m     \"\"\"\n\u001b[1;32m-> 1978\u001b[1;33m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0m\u001b[0;32m   1979\u001b[0m                     signatures, options)\n\u001b[0;32m   1980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m    131\u001b[0m         model, filepath, overwrite, include_optimizer)\n\u001b[0;32m    132\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0m\u001b[0;32m    134\u001b[0m                           signatures, options)\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;31m# we use the default replica context here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_default_replica_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m       \u001b[0msave_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[0;32m    982\u001b[0m   ckpt_options = checkpoint_options.CheckpointOptions(\n\u001b[0;32m    983\u001b[0m       experimental_io_device=options.experimental_io_device)\n\u001b[1;32m--> 984\u001b[1;33m   object_saver.save(utils_impl.get_variables_path(export_dir),\n\u001b[0m\u001b[0;32m    985\u001b[0m                     options=ckpt_options)\n\u001b[0;32m    986\u001b[0m   builder_impl.copy_assets_to_destination_dir(asset_info.asset_filename_map,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, checkpoint_number, session, options)\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1199\u001b[1;33m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[0m\u001b[0;32m   1200\u001b[0m         file_prefix_tensor, object_graph_tensor, options)\n\u001b[0;32m   1201\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[1;34m(self, file_prefix, object_graph_tensor, options)\u001b[0m\n\u001b[0;32m   1143\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[0;32m   1144\u001b[0m       \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m       \u001b[0msave_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mtf_function_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msave_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    267\u001b[0m           \u001b[1;31m# initial read operations should be placed on the SaveableObject's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m           \u001b[1;31m# device.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m           \u001b[0msharded_saves\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0msave_device\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_io_device\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"cpu:0\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mio_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_slices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[1;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[0;32m   1727\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1728\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1729\u001b[1;33m       return save_v2_eager_fallback(\n\u001b[0m\u001b[0;32m   1730\u001b[0m           \u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m           ctx=_ctx)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2_eager_fallback\u001b[1;34m(prefix, tensor_names, shape_and_slices, tensors, name, ctx)\u001b[0m\n\u001b[0;32m   1748\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1749\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"dtypes\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_dtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1750\u001b[1;33m   _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0m\u001b[0;32m   1751\u001b[0m                              ctx=ctx, name=name)\n\u001b[0;32m   1752\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Failed to create a NewWriteableFile: model_2\\variables\\variables_temp_d8965615a90945f2be889de340f7d15d/part-00000-of-00001.data-00000-of-00001.tempstate18400128457331505972 : The system cannot find the path specified.\r\n; No such process [Op:SaveV2]"
     ]
    }
   ],
   "source": [
    "model_2.save('model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
