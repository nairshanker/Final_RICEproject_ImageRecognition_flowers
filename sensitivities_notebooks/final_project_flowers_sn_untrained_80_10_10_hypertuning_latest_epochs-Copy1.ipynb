{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data source\n",
    "\n",
    "Data for download: https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
    "\n",
    "Resources used as reference:\n",
    "1) Training the image classifier to recognize different species of flowers:\n",
    "https://www.kaggle.com/dtosidis/flower-classifier-tensorflow\n",
    "  \n",
    "2) Loading and preprocessing an image dataset\n",
    "https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "3) Data augmentation\n",
    "https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "\n",
    "4) Image classification\n",
    "https://www.tensorflow.org/tutorials/images/classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     active environment : Mlearning\n",
      "    active env location : C:\\ProgramData\\Anaconda3\\envs\\Mlearning\n",
      "            shell level : 2\n",
      "       user config file : C:\\Users\\nairs\\.condarc\n",
      " populated config files : C:\\Users\\nairs\\.condarc\n",
      "          conda version : 4.8.3\n",
      "    conda-build version : 3.18.11\n",
      "         python version : 3.7.6.final.0\n",
      "       virtual packages : __cuda=10.2\n",
      "       base environment : C:\\ProgramData\\Anaconda3  (read only)\n",
      "           channel URLs : https://repo.anaconda.com/pkgs/main/win-64\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\n",
      "                          https://repo.anaconda.com/pkgs/r/win-64\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\n",
      "                          https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "                          https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "          package cache : C:\\ProgramData\\Anaconda3\\pkgs\n",
      "                          C:\\Users\\nairs\\.conda\\pkgs\n",
      "                          C:\\Users\\nairs\\AppData\\Local\\conda\\conda\\pkgs\n",
      "       envs directories : C:\\Users\\nairs\\.conda\\envs\n",
      "                          C:\\ProgramData\\Anaconda3\\envs\n",
      "                          C:\\Users\\nairs\\AppData\\Local\\conda\\conda\\envs\n",
      "               platform : win-64\n",
      "             user-agent : conda/4.8.3 requests/2.22.0 CPython/3.7.6 Windows/10 Windows/10.0.18362\n",
      "          administrator : False\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\ProgramData\\Anaconda3\\envs\\Mlearning:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "absl-py                   0.10.0                   pypi_0    pypi\n",
      "aiohttp                   3.6.2                    pypi_0    pypi\n",
      "argon2-cffi               20.1.0           py38he774522_1  \n",
      "astroid                   2.4.2                    pypi_0    pypi\n",
      "astunparse                1.6.3                    pypi_0    pypi\n",
      "async-timeout             3.0.1                    pypi_0    pypi\n",
      "async_generator           1.10                       py_0  \n",
      "attrs                     20.2.0                     py_0  \n",
      "backcall                  0.2.0                      py_0  \n",
      "blas                      1.0                         mkl  \n",
      "bleach                    3.2.1                      py_0  \n",
      "ca-certificates           2020.7.22                     0  \n",
      "cachetools                4.1.1                    pypi_0    pypi\n",
      "certifi                   2020.6.20                py38_0  \n",
      "cffi                      1.14.3           py38h7a1dbc1_0  \n",
      "chardet                   3.0.4                    pypi_0    pypi\n",
      "click                     7.1.2                      py_0  \n",
      "colorama                  0.4.3                      py_0  \n",
      "console_shortcut          0.1.1                         4  \n",
      "cycler                    0.10.0                     py_2    conda-forge\n",
      "decorator                 4.4.2                      py_0  \n",
      "defusedxml                0.6.0                      py_0  \n",
      "dill                      0.3.2                    pypi_0    pypi\n",
      "dm-tree                   0.1.5                    pypi_0    pypi\n",
      "entrypoints               0.3                      py38_0  \n",
      "flask                     1.1.2                      py_0  \n",
      "freetype                  2.10.2               hd328e21_0    conda-forge\n",
      "future                    0.18.2                   pypi_0    pypi\n",
      "gast                      0.3.3                    pypi_0    pypi\n",
      "google-auth               1.22.0                   pypi_0    pypi\n",
      "google-auth-oauthlib      0.4.1                    pypi_0    pypi\n",
      "google-pasta              0.2.0                    pypi_0    pypi\n",
      "googleapis-common-protos  1.52.0                   pypi_0    pypi\n",
      "grpcio                    1.32.0                   pypi_0    pypi\n",
      "h5py                      2.10.0                   pypi_0    pypi\n",
      "icu                       67.1                 h33f27b4_0    conda-forge\n",
      "idna                      2.10                     pypi_0    pypi\n",
      "importlib-metadata        2.0.0                      py_1  \n",
      "importlib-resources       3.0.0                    pypi_0    pypi\n",
      "importlib_metadata        2.0.0                         1  \n",
      "intel-openmp              2020.2                      254  \n",
      "ipykernel                 5.3.4            py38h5ca1d4c_0  \n",
      "ipython                   7.18.1           py38h5ca1d4c_0  \n",
      "ipython_genutils          0.2.0                    py38_0  \n",
      "isort                     5.6.3                    pypi_0    pypi\n",
      "itsdangerous              1.1.0                      py_0  \n",
      "jedi                      0.17.2                   py38_0  \n",
      "jinja2                    2.11.2                     py_0  \n",
      "jpeg                      9d                   he774522_0    conda-forge\n",
      "jsonschema                3.2.0                    py38_1  \n",
      "jupyter_client            6.1.7                      py_0  \n",
      "jupyter_core              4.6.3                    py38_0  \n",
      "jupyterlab_pygments       0.1.2                      py_0  \n",
      "keras                     2.4.3                    pypi_0    pypi\n",
      "keras-preprocessing       1.1.2                    pypi_0    pypi\n",
      "kiwisolver                1.2.0            py38heaebd3c_0    conda-forge\n",
      "lazy-object-proxy         1.4.3                    pypi_0    pypi\n",
      "libclang                  10.0.1          default_hf44288c_1    conda-forge\n",
      "libpng                    1.6.37               ha81a0f5_2    conda-forge\n",
      "libsodium                 1.0.18               h62dcd97_0  \n",
      "libtiff                   4.1.0                h885aae3_6    conda-forge\n",
      "lz4-c                     1.9.2                h62dcd97_2    conda-forge\n",
      "m2w64-gcc-libgfortran     5.3.0                         6  \n",
      "m2w64-gcc-libs            5.3.0                         7  \n",
      "m2w64-gcc-libs-core       5.3.0                         7  \n",
      "m2w64-gmp                 6.1.0                         2  \n",
      "m2w64-libwinpthread-git   5.0.0.4634.697f757               2  \n",
      "markdown                  3.2.2                    pypi_0    pypi\n",
      "markupsafe                1.1.1            py38he774522_0  \n",
      "matplotlib                3.3.2                         0    conda-forge\n",
      "matplotlib-base           3.3.2            py38hfb9ee82_0    conda-forge\n",
      "mccabe                    0.6.1                    pypi_0    pypi\n",
      "mistune                   0.8.4           py38he774522_1000  \n",
      "mkl                       2020.2                      256  \n",
      "mkl-service               2.3.0            py38hb782905_0  \n",
      "mkl_fft                   1.2.0            py38h45dec08_0  \n",
      "mkl_random                1.1.1            py38h47e9c7a_0  \n",
      "mrjob                     0.7.4                    pypi_0    pypi\n",
      "msys2-conda-epoch         20160418                      1  \n",
      "multidict                 4.7.6                    pypi_0    pypi\n",
      "nbclient                  0.5.0                      py_0  \n",
      "nbconvert                 6.0.7                    py38_0  \n",
      "nbformat                  5.0.7                      py_0  \n",
      "nest-asyncio              1.4.1                      py_0  \n",
      "notebook                  6.1.4                    py38_0  \n",
      "numpy                     1.18.5                   pypi_0    pypi\n",
      "oauthlib                  3.1.0                    pypi_0    pypi\n",
      "olefile                   0.46                       py_0    conda-forge\n",
      "openssl                   1.1.1h               he774522_0  \n",
      "opt-einsum                3.3.0                    pypi_0    pypi\n",
      "packaging                 20.4                       py_0  \n",
      "pandas                    1.1.1            py38ha925a31_0  \n",
      "pandoc                    2.10.1                        0  \n",
      "pandocfilters             1.4.2                    py38_1  \n",
      "parso                     0.7.0                      py_0  \n",
      "pickleshare               0.7.5                 py38_1000  \n",
      "pillow                    7.2.0            py38h7011068_1    conda-forge\n",
      "pip                       20.2.2                   py38_0  \n",
      "prometheus_client         0.8.0                      py_0  \n",
      "promise                   2.3                      pypi_0    pypi\n",
      "prompt-toolkit            3.0.7                      py_0  \n",
      "protobuf                  3.13.0                   pypi_0    pypi\n",
      "pyasn1                    0.4.8                    pypi_0    pypi\n",
      "pyasn1-modules            0.2.8                    pypi_0    pypi\n",
      "pycparser                 2.20                       py_2  \n",
      "pygments                  2.7.1                      py_0  \n",
      "pylint                    2.6.0                    pypi_0    pypi\n",
      "pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\n",
      "pyqt                      5.12.3           py38h6538335_1    conda-forge\n",
      "pyqt5-sip                 4.19.18                  pypi_0    pypi\n",
      "pyqtwebengine             5.12.1                   pypi_0    pypi\n",
      "pyrsistent                0.17.3           py38he774522_0  \n",
      "python                    3.8.5                h5fd99cc_1  \n",
      "python-dateutil           2.8.1                      py_0  \n",
      "python_abi                3.8                      1_cp38    conda-forge\n",
      "pytz                      2020.1                     py_0  \n",
      "pywin32                   227              py38he774522_1  \n",
      "pywinpty                  0.5.7                    py38_0  \n",
      "pyyaml                    5.3.1                    pypi_0    pypi\n",
      "pyzmq                     19.0.2           py38ha925a31_1  \n",
      "qt                        5.12.6               hb2cf2c5_0    conda-forge\n",
      "requests                  2.24.0                   pypi_0    pypi\n",
      "requests-oauthlib         1.3.0                    pypi_0    pypi\n",
      "rsa                       4.6                      pypi_0    pypi\n",
      "scipy                     1.5.2                    pypi_0    pypi\n",
      "send2trash                1.5.0                    py38_0  \n",
      "setuptools                49.6.0                   py38_1  \n",
      "six                       1.15.0                     py_0  \n",
      "sqlite                    3.33.0               h2a8f88b_0  \n",
      "tensorboard               2.3.0                    pypi_0    pypi\n",
      "tensorboard-plugin-wit    1.7.0                    pypi_0    pypi\n",
      "tensorflow                2.3.1                    pypi_0    pypi\n",
      "tensorflow-datasets       4.0.1                    pypi_0    pypi\n",
      "tensorflow-estimator      2.3.0                    pypi_0    pypi\n",
      "tensorflow-hub            0.9.0                    pypi_0    pypi\n",
      "tensorflow-metadata       0.24.0                   pypi_0    pypi\n",
      "termcolor                 1.1.0                    pypi_0    pypi\n",
      "terminado                 0.9.1                    py38_0  \n",
      "testpath                  0.4.4                      py_0  \n",
      "tk                        8.6.10               he774522_0    conda-forge\n",
      "toml                      0.10.1                   pypi_0    pypi\n",
      "tornado                   6.0.4            py38hfa6e2cd_0    conda-forge\n",
      "tqdm                      4.50.2                   pypi_0    pypi\n",
      "traitlets                 5.0.4                      py_0  \n",
      "urllib3                   1.25.10                  pypi_0    pypi\n",
      "vc                        14.1                 h0510ff6_4  \n",
      "vs2015_runtime            14.16.27012          hf0eaf9b_3  \n",
      "wcwidth                   0.2.5                      py_0  \n",
      "webencodings              0.5.1                    py38_1  \n",
      "werkzeug                  1.0.1                      py_0  \n",
      "wheel                     0.35.1                     py_0  \n",
      "wincertstore              0.2                      py38_0  \n",
      "winpty                    0.4.3                         4  \n",
      "wrapt                     1.12.1                   pypi_0    pypi\n",
      "xz                        5.2.5                h62dcd97_1    conda-forge\n",
      "yarl                      1.6.0                    pypi_0    pypi\n",
      "zeromq                    4.3.2                ha925a31_3  \n",
      "zipp                      3.3.0                      py_0  \n",
      "zlib                      1.2.11               h62dcd97_4  \n",
      "zstd                      1.4.5                h1f3a1b7_2    conda-forge\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.2-cp38-cp38-win_amd64.whl (6.8 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\envs\\mlearning\\lib\\site-packages (from scikit-learn) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\envs\\mlearning\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.17.0-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-0.17.0 scikit-learn-0.23.2 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import pathlib\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import (\n",
    "    VGG19, \n",
    "    preprocess_input, \n",
    "    decode_predictions\n",
    ")\n",
    "\n",
    "#New method for test train split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/ShankersDocs/EDUCATION/RICE_Bootcamp_DataAnalytics/FinalProject_Img_Recognition_Flowers/Final_RICEproject_ImageRecognition_flowers\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'flower_photos'\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "# print(image_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification\n",
    "https://www.tensorflow.org/tutorials/images/classification?hl=zh-tw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Size\n",
    "* 32, 64, 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epochs\n",
    "* From 1 to 100\n",
    "* We will use accuracy score on the validation data to find the best epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will use the accuracy score on the validation data to find the best hyperparameter of the model\n",
    "* Once we find the best hyperparameter of the model. we train the model using that hyperparameter and then estimate the model performance on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating datasets\n",
    "https://keras.io/examples/vision/image_classification_from_scratch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for training.\n"
     ]
    }
   ],
   "source": [
    "# When the subset below is defined as \"training\" the 0.2 validation split takes 80% of the data as the training set\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  'flower_photos',\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 367 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# When the subset below is defined as \"validation\" the 0.1 validation split takes 10% of the data as the validation set\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  'flower_photos',\n",
    "  validation_split=0.1,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 367 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# When the subset below is defined as \"validation\" the 0.1 validation split takes 10% of the data as the test set\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  'flower_photos',\n",
    "  validation_split=0.1,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling the data\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Rescaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the data (trainign and validation datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "normalized_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "normalized_val_ds =  val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_train_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autotune is done to cache data and make processing and resource mgmt more effieicient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_train_ds = normalized_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "normalized_val_ds = normalized_val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_classes = 5\n",
    "num_classes = len(class_names)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 (Sequential Model)\n",
    "https://www.tensorflow.org/guide/keras/sequential_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  layers.Conv2D(128, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-a258a8b5efdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Mlearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   2349\u001b[0m     \"\"\"\n\u001b[0;32m   2350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2351\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   2352\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2353\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 8/92 [=>............................] - ETA: 3:11 - loss: 1.6089 - accuracy: 0.1992"
     ]
    }
   ],
   "source": [
    "history = model_2.fit(train_ds,validation_data= val_ds, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the loss and accuracy values achieved during training for the training and validation set.\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model perofrmance on the test data\n",
    "* This is done at the end after you have completed hyperparamter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 7s 599ms/step - loss: 0.9396 - accuracy: 0.6431\n",
      "test loss, test acc: [0.9395563006401062, 0.6430517435073853]\n"
     ]
    }
   ],
   "source": [
    "results = model_2.evaluate(test_ds)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY MODEL WITH DIFFERENT LOSS PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(\n",
    "  optimizer='adam',\n",
    "  loss = tf.keras.losses.categorical_crossentropy(class_names,class_names),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save('C:/Users/nairs/Desktop/model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
